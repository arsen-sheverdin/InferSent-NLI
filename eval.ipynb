{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/AS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "[nltk_data] Downloading package punkt to /Users/AS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/AS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n",
      "next\n",
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n",
      "next\n",
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "import dill\n",
    "\n",
    "print('next')\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import torch\n",
    "import torchtext.vocab as vocab\n",
    "import time\n",
    "\n",
    "\n",
    "from torchtext.data import Field \n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data import BucketIterator\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import tensorboard\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42)\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "\n",
    "from prepare_SNLI import *\n",
    "from utils_eval import *\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    model_name = 'AWE'\n",
    "    seed = 42\n",
    "    checkpoint_path = \"lisalogs/AWE/checkpoints/epoch=26-step=225329.ckpt\"\n",
    "    path_for_logs = 'Successful_eval'\n",
    "    tokenize = True\n",
    "    hidden_dim = 2048\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "args_AWE=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split complete\n",
      "time for split 177.79389095306396\n",
      "dict_keys(['premise', 'hypothesis', 'label'])\n",
      "dict_values([['a', 'person', 'on', 'a', 'horse', 'jumps', 'over', 'a', 'broken', 'down', 'airplane', '.'], ['a', 'person', 'is', 'training', 'his', 'horse', 'for', 'a', 'competition', '.'], 'neutral'])\n",
      "build vocab complete\n"
     ]
    }
   ],
   "source": [
    "s = SNLI(args_AWE)\n",
    "train_iter, dev_iter, test_iter, text, label = s.get_iterators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(37179, 300)\n"
     ]
    }
   ],
   "source": [
    "cp_path = args_AWE.checkpoint_path\n",
    "\n",
    "logger = TensorBoardLogger('Successful_eval', name= args_AWE.model_name)\n",
    "trainer = Trainer(\n",
    "        logger=logger,\n",
    "    )\n",
    "model_AWE = AverageEmbeddings.load_from_checkpoint(\n",
    "                                         cp_path,config = args_AWE, \n",
    "                                         text = text, \n",
    "                                         train_iter = train_iter, \n",
    "                                         dev_iter   = dev_iter,\n",
    "                                         test_iter  = test_iter)\n",
    "print(model_AWE.nli_net.encoder.embedding)\n",
    "# trainer.test(model_AWE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arguments for BiLSTM\n",
    "class Args:\n",
    "    model_name = 'BiLSTM'\n",
    "    seed = 42\n",
    "#     checkpoint_path = \"lisalogs/LSTM/checkpoints/epoch=8-step=72963.ckpt\"\n",
    "    checkpoint_path = \"lisalogs/BiLSTM/checkpoints/epoch=8-step=77255.ckpt\"\n",
    "    path_for_logs = 'Successful_eval'\n",
    "    tokenize = True\n",
    "    hidden_dim = 2048\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     \n",
    "args_BiLSTM=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/AS/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split complete\n",
      "time for split 414.0137052536011\n",
      "dict_keys(['premise', 'hypothesis', 'label'])\n",
      "dict_values([['a', 'person', 'on', 'a', 'horse', 'jumps', 'over', 'a', 'broken', 'down', 'airplane', '.'], ['a', 'person', 'is', 'training', 'his', 'horse', 'for', 'a', 'competition', '.'], 'neutral'])\n",
      "build vocab complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# s = SNLI(args_BiLSTM)\n",
    "# train_iter, dev_iter, test_iter, text, label = s.get_iterators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(37179, 300, padding_idx=1)\n"
     ]
    }
   ],
   "source": [
    "cp_path = args_BiLSTM.checkpoint_path\n",
    "\n",
    "logger = TensorBoardLogger('Successful_eval', name= args_BiLSTM.model_name)\n",
    "trainer = Trainer(\n",
    "        logger=logger,\n",
    "    )\n",
    "model_BiLSTM = Recurrent.load_from_checkpoint(\n",
    "                                         cp_path,config = args_BiLSTM, \n",
    "                                         text = text, \n",
    "                                         train_iter = train_iter, \n",
    "                                         dev_iter   = dev_iter,\n",
    "                                         test_iter  = test_iter)\n",
    "print(model_BiLSTM.nli_net.encoder.embedding)\n",
    "# trainer.test(model_BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(37179, 300, padding_idx=1)\n"
     ]
    }
   ],
   "source": [
    "cp_path = args_BiLSTM.checkpoint_path\n",
    "\n",
    "logger = TensorBoardLogger('Successful_eval', name= args_BiLSTM.model_name)\n",
    "trainer = Trainer(\n",
    "        logger=logger,\n",
    "    )\n",
    "model_BiLSTM = Recurrent.load_from_checkpoint(\n",
    "                                         cp_path,config = args_BiLSTM, \n",
    "                                         text = text, \n",
    "                                         train_iter = train_iter, \n",
    "                                         dev_iter   = dev_iter,\n",
    "                                         test_iter  = test_iter)\n",
    "print(model_BiLSTM.nli_net.encoder.embedding)\n",
    "# trainer.test(model_BiLSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Arguments for LSTM\n",
    "class Args:\n",
    "    model_name = 'LSTM'\n",
    "    seed = 42\n",
    "    checkpoint_path = \"lisalogs/LSTM/checkpoints/epoch=8-step=72963.ckpt\"\n",
    "#     checkpoint_path = \"lisalogs/BiLSTM/checkpoints/epoch=8-step=77255.ckpt\"\n",
    "    path_for_logs = 'Successful_eval'\n",
    "    tokenize = True\n",
    "    hidden_dim = 2048\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args_LSTM=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(37179, 300, padding_idx=1)\n"
     ]
    }
   ],
   "source": [
    "cp_path = args_LSTM.checkpoint_path\n",
    "\n",
    "logger = TensorBoardLogger('Successful_eval', name= args_LSTM.model_name)\n",
    "trainer = Trainer(\n",
    "        logger=logger,\n",
    "    )\n",
    "model_LSTM = Recurrent.load_from_checkpoint(\n",
    "                                         cp_path,config = args_LSTM, \n",
    "                                         text = text, \n",
    "                                         train_iter = train_iter, \n",
    "                                         dev_iter   = dev_iter,\n",
    "                                         test_iter  = test_iter)\n",
    "print(model_LSTM.nli_net.encoder.embedding)\n",
    "# trainer.test(model_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/AS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Global seed set to 42\n",
      "[nltk_data] Downloading package punkt to /Users/AS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n",
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n",
      "next\n",
      "/Users/AS/anaconda3/envs/atcs-nli-representations/bin/python\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "print(sys.executable)\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__\n",
    "import torchtext\n",
    "from main_recurrent import *\n",
    "from collections import Counter\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AS/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "2021-04-19 08:38:18,528 : ***** Transfer task : MR *****\n",
      "\n",
      "\n",
      "2021-04-19 08:38:18,539 : Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-19 08:38:30,214 : Generating sentence embeddings\n",
      "2021-04-19 08:38:30,236 : Generated sentence embeddings\n",
      "2021-04-19 08:38:30,238 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spiderman', 'rocks']\n",
      "['effective', 'but', 'too-tepid', 'biopic']\n",
      "['simplistic', ',', 'silly', 'and', 'tedious', '.']\n",
      "['interesting', ',', 'but', 'not', 'compelling', '.']\n",
      "['illuminating', 'if', 'overly', 'talky', 'documentary', '.']\n",
      "['light', ',', 'cute', 'and', 'forgettable', '.']\n",
      "['not', 'so', 'much', 'farcical', 'as', 'sour', '.']\n",
      "['a', 'sentimental', 'mess', 'that', 'never', 'rings', 'true', '.']\n",
      "['a', 'masterpiece', 'four', 'years', 'in', 'the', 'making', '.']\n",
      "['offers', 'that', 'rare', 'combination', 'of', 'entertainment', 'and', 'education', '.']\n",
      "['a', 'thoughtful', ',', 'provocative', ',', 'insistently', 'humanizing', 'film', '.']\n",
      "['occasionally', 'melodramatic', ',', 'it', \"'s\", 'also', 'extremely', 'effective', '.']\n",
      "['one', 'of', 'the', 'greatest', 'family-oriented', ',', 'fantasy-adventure', 'movies', 'ever', '.']\n",
      "['offers', 'a', 'breath', 'of', 'the', 'fresh', 'air', 'of', 'true', 'sophistication', '.']\n",
      "['this', '100-minute', 'movie', 'only', 'has', 'about', '25', 'minutes', 'of', 'decent', 'material', '.']\n",
      "['ultimately', ',', 'it', 'ponders', 'the', 'reasons', 'we', 'need', 'stories', 'so', 'much', '.']\n",
      "['unfortunately', 'the', 'story', 'and', 'the', 'actors', 'are', 'served', 'with', 'a', 'hack', 'script', '.']\n",
      "['what', 'really', 'surprises', 'about', 'wisegirls', 'is', 'its', 'low-key', 'quality', 'and', 'genuine', 'tenderness', '.']\n",
      "['guaranteed', 'to', 'move', 'anyone', 'who', 'ever', 'shook', ',', 'rattled', ',', 'or', 'rolled', '.']\n",
      "['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slice', 'of', 'asian', 'cinema', '.']\n",
      "['an', 'idealistic', 'love', 'story', 'that', 'brings', 'out', 'the', 'latent', '15-year-old', 'romantic', 'in', 'everyone', '.']\n",
      "['ms', '.', 'fulford-wierzbicki', 'is', 'almost', 'spooky', 'in', 'her', 'sulky', ',', 'calculating', 'lolita', 'turn', '.']\n",
      "['a', 'visually', 'flashy', 'but', 'narratively', 'opaque', 'and', 'emotionally', 'vapid', 'exercise', 'in', 'style', 'and', 'mystification', '.']\n",
      "['this', 'is', 'a', 'film', 'well', 'worth', 'seeing', ',', 'talking', 'and', 'singing', 'heads', 'and', 'all', '.']\n",
      "['it', \"'s\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.']\n",
      "['the', 'criticism', 'never', 'rises', 'above', 'easy', ',', 'cynical', 'potshots', 'at', 'morally', 'bankrupt', 'characters', '.', '.', '.']\n",
      "['a', 'disturbing', 'and', 'frighteningly', 'evocative', 'assembly', 'of', 'imagery', 'and', 'hypnotic', 'music', 'composed', 'by', 'philip', 'glass', '.']\n",
      "['scores', 'a', 'few', 'points', 'for', 'doing', 'what', 'it', 'does', 'with', 'a', 'dedicated', 'and', 'good-hearted', 'professionalism', '.']\n",
      "['fuller', 'would', 'surely', 'have', 'called', 'this', 'gutsy', 'and', 'at', 'times', 'exhilarating', 'movie', 'a', 'great', 'yarn', '.']\n",
      "['the', 'movie', \"'s\", 'ripe', ',', 'enrapturing', 'beauty', 'will', 'tempt', 'those', 'willing', 'to', 'probe', 'its', 'inscrutable', 'mysteries', '.']\n",
      "['though', 'everything', 'might', 'be', 'literate', 'and', 'smart', ',', 'it', 'never', 'took', 'off', 'and', 'always', 'seemed', 'static', '.']\n",
      "['cantet', 'perfectly', 'captures', 'the', 'hotel', 'lobbies', ',', 'two-lane', 'highways', ',', 'and', 'roadside', 'cafes', 'that', 'permeate', 'vincent', \"'s\", 'days']\n",
      "['the', 'party', 'scenes', 'deliver', 'some', 'tawdry', 'kicks', '.', 'the', 'rest', 'of', 'the', 'film', '.', '.', '.', 'is', 'dudsville', '.']\n",
      "['on', 'its', 'own', ',', 'it', \"'s\", 'not', 'very', 'interesting', '.', 'as', 'a', 'remake', ',', 'it', \"'s\", 'a', 'pale', 'imitation', '.']\n",
      "['perhaps', 'no', 'picture', 'ever', 'made', 'has', 'more', 'literally', 'showed', 'that', 'the', 'road', 'to', 'hell', 'is', 'paved', 'with', 'good', 'intentions', '.']\n",
      "['a', 'masterful', 'film', 'from', 'a', 'master', 'filmmaker', ',', 'unique', 'in', 'its', 'deceptive', 'grimness', ',', 'compelling', 'in', 'its', 'fatalist', 'worldview', '.']\n",
      "['newton', 'draws', 'our', 'attention', 'like', 'a', 'magnet', ',', 'and', 'acts', 'circles', 'around', 'her', 'better', 'known', 'co-star', ',', 'mark', 'wahlberg', '.']\n",
      "['[', 'garbus', ']', 'discards', 'the', 'potential', 'for', 'pathological', 'study', ',', 'exhuming', 'instead', ',', 'the', 'skewed', 'melodrama', 'of', 'the', 'circumstantial', 'situation', '.']\n",
      "['if', 'you', 'sometimes', 'like', 'to', 'go', 'to', 'the', 'movies', 'to', 'have', 'fun', ',', 'wasabi', 'is', 'a', 'good', 'place', 'to', 'start', '.']\n",
      "['exploitative', 'and', 'largely', 'devoid', 'of', 'the', 'depth', 'or', 'sophistication', 'that', 'would', 'make', 'watching', 'such', 'a', 'graphic', 'treatment', 'of', 'the', 'crimes', 'bearable', '.']\n",
      "['the', 'story', 'is', 'also', 'as', 'unoriginal', 'as', 'they', 'come', ',', 'already', 'having', 'been', 'recycled', 'more', 'times', 'than', 'i', \"'d\", 'care', 'to', 'count', '.']\n",
      "['there', 'is', 'a', 'difference', 'between', 'movies', 'with', 'the', 'courage', 'to', 'go', 'over', 'the', 'top', 'and', 'movies', 'that', 'do', \"n't\", 'care', 'about', 'being', 'stupid']\n",
      "['nothing', 'here', 'seems', 'as', 'funny', 'as', 'it', 'did', 'in', 'analyze', 'this', ',', 'not', 'even', 'joe', 'viterelli', 'as', 'de', 'niro', \"'s\", 'right-hand', 'goombah', '.']\n",
      "['emerges', 'as', 'something', 'rare', ',', 'an', 'issue', 'movie', 'that', \"'s\", 'so', 'honest', 'and', 'keenly', 'observed', 'that', 'it', 'does', \"n't\", 'feel', 'like', 'one', '.']\n",
      "['an', 'utterly', 'compelling', \"'who\", 'wrote', 'it', \"'\", 'in', 'which', 'the', 'reputation', 'of', 'the', 'most', 'famous', 'author', 'who', 'ever', 'lived', 'comes', 'into', 'question', '.']\n",
      "['not', 'for', 'everyone', ',', 'but', 'for', 'those', 'with', 'whom', 'it', 'will', 'connect', ',', 'it', \"'s\", 'a', 'nice', 'departure', 'from', 'standard', 'moviegoing', 'fare', '.']\n",
      "['(', 'wendigo', 'is', ')', 'why', 'we', 'go', 'to', 'the', 'cinema', ':', 'to', 'be', 'fed', 'through', 'the', 'eye', ',', 'the', 'heart', ',', 'the', 'mind', '.']\n",
      "['it', 'helps', 'that', 'lil', 'bow', 'wow', '.', '.', '.', 'tones', 'down', 'his', 'pint-sized', 'gangsta', 'act', 'to', 'play', 'someone', 'who', 'resembles', 'a', 'real', 'kid', '.']\n",
      "['while', 'the', 'performances', 'are', 'often', 'engaging', ',', 'this', 'loose', 'collection', 'of', 'largely', 'improvised', 'numbers', 'would', 'probably', 'have', 'worked', 'better', 'as', 'a', 'one-hour', 'tv', 'documentary', '.']\n",
      "['here', ',', 'common', 'sense', 'flies', 'out', 'the', 'window', ',', 'along', 'with', 'the', 'hail', 'of', 'bullets', ',', 'none', 'of', 'which', 'ever', 'seem', 'to', 'hit', 'sascha', '.']\n",
      "['as', 'exciting', 'as', 'all', 'this', 'exoticism', 'might', 'sound', 'to', 'the', 'typical', 'pax', 'viewer', ',', 'the', 'rest', 'of', 'us', 'will', 'be', 'lulled', 'into', 'a', 'coma', '.']\n",
      "['all', 'the', 'more', 'disquieting', 'for', 'its', 'relatively', 'gore-free', 'allusions', 'to', 'the', 'serial', 'murders', ',', 'but', 'it', 'falls', 'down', 'in', 'its', 'attempts', 'to', 'humanize', 'its', 'subject', '.']\n",
      "['the', 'film', 'provides', 'some', 'great', 'insight', 'into', 'the', 'neurotic', 'mindset', 'of', 'all', 'comics', '--', 'even', 'those', 'who', 'have', 'reached', 'the', 'absolute', 'top', 'of', 'the', 'game', '.']\n",
      "['somewhere', 'in', 'the', 'middle', ',', 'the', 'film', 'compels', ',', 'as', 'demme', 'experiments', 'he', 'harvests', 'a', 'few', 'movie', 'moment', 'gems', ',', 'but', 'the', 'field', 'of', 'roughage', 'dominates', '.']\n",
      "['stupid', ',', 'infantile', ',', 'redundant', ',', 'sloppy', ',', 'over-the-top', ',', 'and', 'amateurish', '.', 'yep', ',', 'it', \"'s\", '``', 'waking', 'up', 'in', 'reno', '.', '``', 'go', 'back', 'to', 'sleep', '.']\n",
      "['steers', 'turns', 'in', 'a', 'snappy', 'screenplay', 'that', 'curls', 'at', 'the', 'edges', ';', 'it', \"'s\", 'so', 'clever', 'you', 'want', 'to', 'hate', 'it', '.', 'but', 'he', 'somehow', 'pulls', 'it', 'off', '.']\n",
      "['if', 'there', \"'s\", 'a', 'way', 'to', 'effectively', 'teach', 'kids', 'about', 'the', 'dangers', 'of', 'drugs', ',', 'i', 'think', 'it', \"'s\", 'in', 'projects', 'like', 'the', '(', 'unfortunately', 'r-rated', ')', 'paid', '.']\n",
      "['on', 'a', 'cutting', 'room', 'floor', 'somewhere', 'lies', '.', '.', '.', 'footage', 'that', 'might', 'have', 'made', 'no', 'such', 'thing', 'a', 'trenchant', ',', 'ironic', 'cultural', 'satire', 'instead', 'of', 'a', 'frustrating', 'misfire', '.']\n",
      "['the', 'execution', 'is', 'so', 'pedestrian', 'that', 'the', 'most', 'positive', 'comment', 'we', 'can', 'make', 'is', 'that', 'rob', 'schneider', 'actually', 'turns', 'in', 'a', 'pretty', 'convincing', 'performance', 'as', 'a', 'prissy', 'teenage', 'girl', '.']\n",
      "['it', 'shows', 'that', 'some', 'studios', 'firmly', 'believe', 'that', 'people', 'have', 'lost', 'the', 'ability', 'to', 'think', 'and', 'will', 'forgive', 'any', 'shoddy', 'product', 'as', 'long', 'as', 'there', \"'s\", 'a', 'little', 'girl-on-girl', 'action', '.']\n",
      "['about', 'the', 'only', 'thing', 'to', 'give', 'the', 'movie', 'points', 'for', 'is', 'bravado', '--', 'to', 'take', 'an', 'entirely', 'stale', 'concept', 'and', 'push', 'it', 'through', 'the', 'audience', \"'s\", 'meat', 'grinder', 'one', 'more', 'time', '.']\n",
      "['a', 'farce', 'of', 'a', 'parody', 'of', 'a', 'comedy', 'of', 'a', 'premise', ',', 'it', 'is', \"n't\", 'a', 'comparison', 'to', 'reality', 'so', 'much', 'as', 'it', 'is', 'a', 'commentary', 'about', 'our', 'knowledge', 'of', 'films', '.']\n",
      "['our', 'culture', 'is', 'headed', 'down', 'the', 'toilet', 'with', 'the', 'ferocity', 'of', 'a', 'frozen', 'burrito', 'after', 'an', 'all-night', 'tequila', 'bender', 'and', 'i', 'know', 'this', 'because', 'i', \"'ve\", 'seen', \"'jackass\", ':', 'the', 'movie', '.', \"'\"]\n",
      "['while', 'it', 'would', 'be', 'easy', 'to', 'give', 'crush', 'the', 'new', 'title', 'of', 'two', 'weddings', 'and', 'a', 'funeral', ',', 'it', \"'s\", 'a', 'far', 'more', 'thoughtful', 'film', 'than', 'any', 'slice', 'of', 'hugh', 'grant', 'whimsy', '.']\n",
      "['such', 'master', 'screenwriting', 'comes', 'courtesy', 'of', 'john', 'pogue', ',', 'the', 'yale', 'grad', 'who', 'previously', 'gave', 'us', '``', 'the', 'skulls', '``', 'and', 'last', 'year', \"'s\", '``', 'rollerball', '.', '``', 'enough', 'said', ',', 'except', ':', 'film', 'overboard', '!']\n",
      "['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', '``', 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.']\n",
      "['like', 'most', 'bond', 'outings', 'in', 'recent', 'years', ',', 'some', 'of', 'the', 'stunts', 'are', 'so', 'outlandish', 'that', 'they', 'border', 'on', 'being', 'cartoonlike', '.', 'a', 'heavy', 'reliance', 'on', 'cgi', 'technology', 'is', 'beginning', 'to', 'creep', 'into', 'the', 'series', '.']\n",
      "['the', 'story', 'loses', 'its', 'bite', 'in', 'a', 'last-minute', 'happy', 'ending', 'that', \"'s\", 'even', 'less', 'plausible', 'than', 'the', 'rest', 'of', 'the', 'picture', '.', 'much', 'of', 'the', 'way', ',', 'though', ',', 'this', 'is', 'a', 'refreshingly', 'novel', 'ride', '.']\n",
      "['with', 'a', 'cast', 'that', 'includes', 'some', 'of', 'the', 'top', 'actors', 'working', 'in', 'independent', 'film', ',', 'lovely', '&', 'amazing', 'involves', 'us', 'because', 'it', 'is', 'so', 'incisive', ',', 'so', 'bleakly', 'amusing', 'about', 'how', 'we', 'go', 'about', 'our', 'lives', '.']\n",
      "['while', 'the', 'ensemble', 'player', 'who', 'gained', 'notice', 'in', 'guy', 'ritchie', \"'s\", 'lock', ',', 'stock', 'and', 'two', 'smoking', 'barrels', 'and', 'snatch', 'has', 'the', 'bod', ',', 'he', \"'s\", 'unlikely', 'to', 'become', 'a', 'household', 'name', 'on', 'the', 'basis', 'of', 'his', 'first', 'starring', 'vehicle', '.']\n",
      "['the', 'movie', \"'s\", 'something-borrowed', 'construction', 'feels', 'less', 'the', 'product', 'of', 'loving', ',', 'well', 'integrated', 'homage', 'and', 'more', 'like', 'a', 'mere', 'excuse', 'for', 'the', 'wan', ',', 'thinly', 'sketched', 'story', '.', 'killing', 'time', ',', 'that', \"'s\", 'all', 'that', \"'s\", 'going', 'on', 'here', '.']\n",
      "['the', 'gorgeously', 'elaborate', 'continuation', 'of', '``', 'the', 'lord', 'of', 'the', 'rings', '``', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'can', 'not', 'adequately', 'describe', 'co-writer/director', 'peter', 'jackson', \"'s\", 'expanded', 'vision', 'of', 'j', '.', 'r', '.', 'r', '.', 'tolkien', \"'s\", 'middle-earth', '.']\n",
      "['at', 'about', '95', 'minutes', ',', 'treasure', 'planet', 'maintains', 'a', 'brisk', 'pace', 'as', 'it', 'races', 'through', 'the', 'familiar', 'story', '.', 'however', ',', 'it', 'lacks', 'grandeur', 'and', 'that', 'epic', 'quality', 'often', 'associated', 'with', 'stevenson', \"'s\", 'tale', 'as', 'well', 'as', 'with', 'earlier', 'disney', 'efforts', '.']\n",
      "['though', 'it', 'is', 'by', 'no', 'means', 'his', 'best', 'work', ',', 'laissez-passer', 'is', 'a', 'distinguished', 'and', 'distinctive', 'effort', 'by', 'a', 'bona-fide', 'master', ',', 'a', 'fascinating', 'film', 'replete', 'with', 'rewards', 'to', 'be', 'had', 'by', 'all', 'willing', 'to', 'make', 'the', 'effort', 'to', 'reap', 'them', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-19 08:38:30,758 : Best param found at split 1: l2reg = 8                 with score 60.95\n",
      "2021-04-19 08:38:31,148 : Best param found at split 2: l2reg = 8                 with score 69.05\n",
      "2021-04-19 08:38:31,535 : Best param found at split 3: l2reg = 8                 with score 62.38\n",
      "2021-04-19 08:38:32,003 : Best param found at split 4: l2reg = 4                 with score 57.38\n",
      "2021-04-19 08:38:32,359 : Best param found at split 5: l2reg = 4                 with score 60.24\n",
      "2021-04-19 08:38:32,816 : Best param found at split 6: l2reg = 8                 with score 60.24\n",
      "2021-04-19 08:38:33,247 : Best param found at split 7: l2reg = 0.25                 with score 56.9\n",
      "2021-04-19 08:38:33,670 : Best param found at split 8: l2reg = 4                 with score 65.95\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-14c68d5e3289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m#     results_recovered = load_obj(name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mseval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_AWE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_AWE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-14c68d5e3289>\u001b[0m in \u001b[0;36mseval\u001b[0;34m(args, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'BiLSTM_output'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI_University/ATCS/Sentence_Representations_from_NLI/SentEval/senteval/engine.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI_University/ATCS/Sentence_Representations_from_NLI/SentEval/senteval/engine.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI_University/ATCS/Sentence_Representations_from_NLI/SentEval/senteval/engine.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI_University/ATCS/Sentence_Representations_from_NLI/SentEval/senteval/binary.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, params, batcher)\u001b[0m\n\u001b[1;32m     55\u001b[0m                   'nhid': params.nhid, 'kfold': params.kfold}\n\u001b[1;32m     56\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInnerKFoldClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdevacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dev acc : {0} Test acc : {1}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestacc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         return {'devacc': devacc, 'acc': testacc, 'ndev': self.n_samples,\n",
      "\u001b[0;32m~/Documents/AI_University/ATCS/Sentence_Representations_from_NLI/SentEval/senteval/tools/validation.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_in_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_in_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                     \u001b[0mregscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_in_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_in_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    756\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[1;32m    757\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[0;32m--> 758\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    617\u001b[0m                                   **options)\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[0;34m(w, X, y)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/atcs-nli-representations/lib/python3.9/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "#\n",
    "\n",
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import numpy as np\n",
    "import logging\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# Set PATHs\n",
    "# path to senteval\n",
    "PATH_TO_SENTEVAL = '../SentEval/'\n",
    "# path to the NLP datasets \n",
    "# PATH_TO_DATA = '../data/downstream'\n",
    "PATH_TO_DATA = '../SentEval/data'\n",
    "# path to glove embeddings\n",
    "PATH_TO_VEC = '../SentEval/pretrained/glove.840B.300d.txt'\n",
    "\n",
    "\n",
    "# import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval\n",
    "from torchtext.data import Field\n",
    "import data\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    params.inputs.build_vocab(samples)\n",
    "    params.inputs.vocab.load_vectors('glove.840B.300d')\n",
    "    params.model.nli_net.encoder.embedding.weight.data = params.inputs.vocab.vectors\n",
    "\n",
    "def batcher(params, batch):\n",
    "\n",
    "    sentences = []\n",
    "    sentences_lens = []\n",
    "    c = 0\n",
    "    for s in batch:\n",
    "        if len(s) == 0:\n",
    "            s = '.'\n",
    "        sentences.append(s)\n",
    "        sentences_lens.append(len(s))\n",
    "    sentences = params.inputs.process(sentences)[0]\n",
    "    sentences = sentences.T\n",
    "    sentence_lens = torch.Tensor(sentences_lens)\n",
    "    if params.args.model_name == 'AWE':\n",
    "        emb = params.model.nli_net.encode(sentences)\n",
    "    else:\n",
    "        emb = params.model.nli_net.encode((sentences, sentence_lens))\n",
    "    return emb.detach().numpy()\n",
    "\n",
    "\n",
    "# Set params for SentEval\n",
    "# we use logistic regression (usepytorch: Fasle) and kfold 10\n",
    "# In this dictionary you can add extra information that you model needs for initialization\n",
    "# for example the path to a dictionary of indices, of hyper parameters\n",
    "# this dictionary is passed to the batched and the prepare fucntions\n",
    "\n",
    "\n",
    "#Parameters from Matyas\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': False, 'kfold': 10}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 3, 'epoch_size': 4}\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "def seval(args, model):\n",
    "    \n",
    "    params_senteval['args'] =  args\n",
    "    params_senteval['model'] =  model\n",
    "    params_senteval['inputs'] = Field(lower=True, tokenize=word_tokenize, include_lengths=True)\n",
    "    \n",
    "    # here you define the NLP taks that your embedding model is going to be evaluated\n",
    "    # in (https://arxiv.org/abs/1802.05883) we use the following :\n",
    "    # SICKRelatedness (Sick-R) needs torch cuda to work (even when using logistic regression), \n",
    "    # but STS14 (semantic textual similarity) is a similar type of semantic task\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "#     transfer_tasks = ['SICKEntailment']\n",
    "    transfer_tasks = ['MR','CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC', 'SICKEntailment' ]\n",
    "    transfer_tasks2 =['SST2', 'TREC', 'MRPC', 'SICKEntailment'] \n",
    "#     transfer_tasks2 =['TREC'] \n",
    "#     'STS12', 'STS13', 'STS14', 'STS15', 'STS16'\n",
    "                        # 'SICKRelatedness', 'STSBenchmark'\n",
    "#                       'MPQA', 'SUBJ', 'SST2', 'TREC',\n",
    "#                       'MRPC', 'SICKEntailment']\n",
    "#                       , 'STS14']\n",
    "    # senteval prints the results and returns a dictionary with the scores\n",
    "#     \n",
    "    if args.model_name == 'LSTM':\n",
    "        name = 'LSTM_output'\n",
    "        \n",
    "    if args.model_name == 'BiLSTM':\n",
    "        name = 'BiLSTM_output'\n",
    "        \n",
    "    results = se.eval(transfer_tasks)\n",
    "    print('\\n\\n')\n",
    "    print(results)\n",
    "    print('\\n\\n')\n",
    "\n",
    "#     save_obj(results, name)\n",
    "#     results_recovered = load_obj(name)\n",
    "    \n",
    "    results2 = se.eval(transfer_tasks2)\n",
    "          \n",
    "    print('\\n\\n')      \n",
    "    print(results2)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "#     save_obj(results, name)\n",
    "#     results_recovered = load_obj(name)\n",
    "\n",
    "seval(args_AWE, model_AWE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TEXT.Field\",\"wb\")as f:\n",
    "     dill.dump(text,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
